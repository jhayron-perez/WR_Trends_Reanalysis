{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d008db20-e241-4887-8a65-52be3aac8b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68d70eb-0066-4f7d-84fb-cd101313f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_climatology(datasettemp):\n",
    "    # Create an empty DataArray to hold the climatology results with the same shape as the input\n",
    "    climatology_rolling = xr.DataArray(\n",
    "        np.full_like(datasettemp.Z, np.nan),  # Initialize with NaNs\n",
    "        coords=datasettemp.coords,\n",
    "        dims=datasettemp.dims\n",
    "    )\n",
    "    climatology_rolling_std = xr.DataArray(\n",
    "        np.full_like(datasettemp.Z, np.nan),  # Initialize with NaNs\n",
    "        coords=datasettemp.coords,\n",
    "        dims=datasettemp.dims\n",
    "    )\n",
    "    data = datasettemp.Z\n",
    "    # Define the window length for climatology\n",
    "    window_length = 30  # years\n",
    "    # Extract the years from the time dimension\n",
    "    years = pd.DatetimeIndex(data['time'].values).year\n",
    "    # Iterate through unique years in the dataset\n",
    "    unique_years = np.unique(years)\n",
    "    for year in unique_years:\n",
    "        # Define the 30-year rolling window for the current year\n",
    "        start_year = year - window_length // 2\n",
    "        end_year = year + window_length // 2\n",
    "        # Select data within the rolling window based on years\n",
    "        window_data = data.sel(time=slice(f'{start_year}-01-01', f'{end_year}-12-31'))\n",
    "        # Compute the day of the year for the windowed data\n",
    "        window_data['dayofyear'] = window_data['time'].dt.dayofyear\n",
    "        # Group by the day of the year and compute the mean climatology\n",
    "        climatology_doy = window_data.groupby('dayofyear').mean(dim='time')\n",
    "        climatology_doy_std = window_data.groupby('dayofyear').std(dim='time')\n",
    "        # Assign the computed climatology back to the rolling DataArray for each day in the year\n",
    "        for doy in range(1, 367):  # Including leap year day if present\n",
    "            try:\n",
    "                # Get the actual day dates in the current year\n",
    "                days_in_year = data.sel(time=str(year)).where(data['time'].dt.dayofyear == doy, drop=True)\n",
    "                # Check if there are days for this DOY in the current year\n",
    "                if not days_in_year['time'].values.size:\n",
    "                    continue\n",
    "                # Assign the computed climatology value to the corresponding days\n",
    "                climatology_value = climatology_doy.sel(dayofyear=doy)\n",
    "                climatology_rolling.loc[{'time': days_in_year['time']}] = climatology_value\n",
    "\n",
    "                climatology_value_std = climatology_doy_std.sel(dayofyear=doy)\n",
    "                climatology_rolling_std.loc[{'time': days_in_year['time']}] = climatology_value_std\n",
    "            except KeyError:\n",
    "                # In case the DOY does not exist in climatology_doy (e.g., Feb 29 in non-leap years)\n",
    "                continue\n",
    "        # Optional: Print progress\n",
    "        # print(f\"Processed climatology for the year: {year}\")\n",
    "    #smooth both things\n",
    "    climatology_rolling = climatology_rolling.to_dataset(name='Z_climo')\n",
    "    climatology_rolling = climatology_rolling.Z_climo.rolling(time=60, center=True, min_periods=29).mean()\n",
    "    climatology_rolling = climatology_rolling.to_dataset()\n",
    "\n",
    "    climatology_rolling_std = climatology_rolling_std.to_dataset(name='Z_climo')\n",
    "    climatology_rolling_std = climatology_rolling_std.Z_climo.rolling(time=60, center=True, min_periods=29).mean()\n",
    "    climatology_rolling_std = climatology_rolling_std.to_dataset()\n",
    "    return climatology_rolling, climatology_rolling_std\n",
    "\n",
    "def fourierfilter(dataarray,cutoff_period=10):\n",
    "    # Compute the Fourier transform along the time axis\n",
    "    fft_data = np.fft.fft(dataarray, axis=0)\n",
    "    # Get the frequencies corresponding to the FFT components\n",
    "    freqs = np.fft.fftfreq(dataarray.shape[0], d=1)  # d=1 assumes daily data; adjust if different\n",
    "    \n",
    "    # Compute the corresponding periods (in days)\n",
    "    periods = np.abs(1 / freqs)\n",
    "    \n",
    "    # Define the cutoff period for high-pass filter (10 days)\n",
    "    cutoff_period = 10\n",
    "    \n",
    "    # Create a mask to filter out low-frequency components (longer than 10 days)\n",
    "    high_pass_mask = periods < cutoff_period\n",
    "    \n",
    "    # Apply the mask to the FFT data (set low-frequency components to zero)\n",
    "    fft_data_filtered = fft_data.copy()\n",
    "    fft_data_filtered[high_pass_mask, :, :] = 0\n",
    "    \n",
    "    # Perform the inverse FFT to get the filtered data back in the time domain\n",
    "    filtered_data = np.fft.ifft(fft_data_filtered, axis=0).real\n",
    "    \n",
    "    # Create a new xarray DataArray to store the filtered data\n",
    "    filtered_anomalies = xr.DataArray(\n",
    "        filtered_data,\n",
    "        dims=dataarray.dims,\n",
    "        coords=dataarray.coords,\n",
    "        attrs=dataarray.attrs\n",
    "    )\n",
    "    return filtered_anomalies\n",
    "\n",
    "def compute_anoms_experiment_complete(name_reanalysis):\n",
    "    name_experiment = unique_names_experiments[id_experiment]\n",
    "    print(f'Started {name_experiment}')\n",
    "    where_files = np.where(names_experiments_all==name_experiment)[0]\n",
    "    files_temp = filenames[where_files]\n",
    "    dataset_temp = extractz500_several_files(files_temp)\n",
    "    \n",
    "    climatology_temp, climatology_std_temp = compute_climatology(dataset_temp)\n",
    "    \n",
    "    anoms = (dataset_temp.Z500 - climatology_temp.Z_climo)/climatology_std_temp.Z_climo\n",
    "    del(climatology_temp)\n",
    "    del(climatology_std_temp)\n",
    "    filtered_anoms = fourierfilter(anoms)\n",
    "    \n",
    "    filtered_anoms = filtered_anoms.to_dataset(name='Z_anoms')\n",
    "    filtered_anoms.to_netcdf(f'{path_outputs_anoms}anoms_{name_experiment}.nc')\n",
    "    print(f'Experiment {name_experiment} complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f054a06-4c84-438d-abff-3b4a8780b3a7",
   "metadata": {},
   "source": [
    "# ERA5 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1b68062-dfdf-48a1-b36d-62ccd7076083",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_origins = '/glade/derecho/scratch/jhayron/Data4WRsClimateChange/ProcessedDataReanalyses/'\n",
    "name_reanalysis = 'ERA5'\n",
    "dataset = xr.open_dataset(f'{path_origins}Z500_{name_reanalysis}.nc')\n",
    "climatology_temp, climatology_std_temp = compute_climatology(dataset)\n",
    "anoms = (dataset.Z - climatology_temp.Z_climo)/climatology_std_temp.Z_climo\n",
    "# del(climatology_temp)\n",
    "# del(climatology_std_temp)\n",
    "filtered_anoms = fourierfilter(anoms)\n",
    "filtered_anoms = filtered_anoms.to_dataset(name='Z_anoms')\n",
    "path_output_anoms = f'{path_origins}Z500Anoms_{name_reanalysis}.nc'\n",
    "filtered_anoms.to_netcdf(path_output_anoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4769b16d-3aba-4eac-84a0-2c5f814050ee",
   "metadata": {},
   "source": [
    "# All the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b497e302-e6da-4173-a4c9-c16388bde229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anoms_reanalysis(name_reanalysis):\n",
    "    path_origins = '/glade/derecho/scratch/jhayron/Data4WRsClimateChange/ProcessedDataReanalyses/'\n",
    "    dataset = xr.open_dataset(f'{path_origins}Z500_{name_reanalysis}.nc')\n",
    "    climatology_temp, climatology_std_temp = compute_climatology(dataset)\n",
    "    anoms = (dataset.Z - climatology_temp.Z_climo)/climatology_std_temp.Z_climo\n",
    "    filtered_anoms = fourierfilter(anoms)\n",
    "    filtered_anoms = filtered_anoms.to_dataset(name='Z_anoms')\n",
    "    path_output_anoms = f'{path_origins}Z500Anoms_{name_reanalysis}.nc'\n",
    "    filtered_anoms.to_netcdf(path_output_anoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1ab7cff5-b385-421e-a8e8-bea3ff7149fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/jhayron/tmp/ipykernel_152345/2029121954.py:67: RuntimeWarning: divide by zero encountered in divide\n",
      "  periods = np.abs(1 / freqs)\n"
     ]
    }
   ],
   "source": [
    "compute_anoms_reanalysis('JRA3Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9a9abed-8f45-450a-b02b-32da9216638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/jhayron/tmp/ipykernel_163922/2029121954.py:67: RuntimeWarning: divide by zero encountered in divide\n",
      "  periods = np.abs(1 / freqs)\n"
     ]
    }
   ],
   "source": [
    "compute_anoms_reanalysis('MERRA2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a0b4890-f0fd-486e-b7d7-2cfa01b26244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/jhayron/tmp/ipykernel_163922/2029121954.py:67: RuntimeWarning: divide by zero encountered in divide\n",
      "  periods = np.abs(1 / freqs)\n"
     ]
    }
   ],
   "source": [
    "compute_anoms_reanalysis('NCEP_NCAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d29dee2-f9a6-4da3-8eb2-a8ae34c703f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/jhayron/tmp/ipykernel_163922/2029121954.py:67: RuntimeWarning: divide by zero encountered in divide\n",
      "  periods = np.abs(1 / freqs)\n"
     ]
    }
   ],
   "source": [
    "compute_anoms_reanalysis('NCEP_DOE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89cb201-6527-4f3e-adb4-b577f99bf917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cnn_wr]",
   "language": "python",
   "name": "conda-env-cnn_wr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
