{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d008db20-e241-4887-8a65-52be3aac8b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/work/jhayron/conda-envs/cnn_wr/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import glob\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.polynomial import polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c68d70eb-0066-4f7d-84fb-cd101313f421",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fourierfilter(dataarray,cutoff_period=10):\n",
    "    # Compute the Fourier transform along the time axis\n",
    "    fft_data = np.fft.fft(dataarray, axis=0)\n",
    "    # Get the frequencies corresponding to the FFT components\n",
    "    freqs = np.fft.fftfreq(dataarray.shape[0], d=1)  # d=1 assumes daily data; adjust if different\n",
    "    \n",
    "    # Compute the corresponding periods (in days)\n",
    "    periods = np.abs(1 / freqs)\n",
    "    \n",
    "    # Define the cutoff period for high-pass filter (10 days)\n",
    "    cutoff_period = 10\n",
    "    \n",
    "    # Create a mask to filter out low-frequency components (longer than 10 days)\n",
    "    high_pass_mask = periods < cutoff_period\n",
    "    \n",
    "    # Apply the mask to the FFT data (set low-frequency components to zero)\n",
    "    fft_data_filtered = fft_data.copy()\n",
    "    fft_data_filtered[high_pass_mask, :, :] = 0\n",
    "    \n",
    "    # Perform the inverse FFT to get the filtered data back in the time domain\n",
    "    filtered_data = np.fft.ifft(fft_data_filtered, axis=0).real\n",
    "    \n",
    "    # Create a new xarray DataArray to store the filtered data\n",
    "    filtered_anomalies = xr.DataArray(\n",
    "        filtered_data,\n",
    "        dims=dataarray.dims,\n",
    "        coords=dataarray.coords,\n",
    "        attrs=dataarray.attrs\n",
    "    )\n",
    "    return filtered_anomalies\n",
    "\n",
    "def compute_anoms_experiment_complete(name_reanalysis):\n",
    "    name_experiment = unique_names_experiments[id_experiment]\n",
    "    print(f'Started {name_experiment}')\n",
    "    where_files = np.where(names_experiments_all==name_experiment)[0]\n",
    "    files_temp = filenames[where_files]\n",
    "    dataset_temp = extractz500_several_files(files_temp)\n",
    "    \n",
    "    climatology_temp, climatology_std_temp = compute_climatology(dataset_temp)\n",
    "    \n",
    "    anoms = (dataset_temp.Z500 - climatology_temp.Z_climo)/climatology_std_temp.Z_climo\n",
    "    del(climatology_temp)\n",
    "    del(climatology_std_temp)\n",
    "    filtered_anoms = fourierfilter(anoms)\n",
    "    \n",
    "    filtered_anoms = filtered_anoms.to_dataset(name='Z_anoms')\n",
    "    filtered_anoms.to_netcdf(f'{path_outputs_anoms}anoms_{name_experiment}.nc')\n",
    "    print(f'Experiment {name_experiment} complete')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f054a06-4c84-438d-abff-3b4a8780b3a7",
   "metadata": {},
   "source": [
    "# ERA5 Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "335a456f-5fed-44b9-bcc5-e2ca67d0cee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detrend_obs(data, train_data, npoly=3):\n",
    "    '''\n",
    "    detrend reanalysis using polynomial fit (for each doy) to the training mean\n",
    "    \n",
    "    data: [time, lat, lon] or [member, time]\n",
    "        reanalysis to detrend \n",
    "    \n",
    "    train_data: [time, lat, lon] or [time]\n",
    "        ensemble mean \n",
    "    \n",
    "    npoly: [int] \n",
    "        order of polynomial, default = 3rd order\n",
    "    '''\n",
    "    # stack lat and lon of ensemble mean data\n",
    "    if len(train_data.shape) == 3:\n",
    "        train_data = train_data.stack(z=('lat', 'lon'))\n",
    " \n",
    "    # stack lat and lon of member data & grab doy information\n",
    "    if len(data.shape) == 3:\n",
    "        data = data.stack(z=('lat', 'lon'))\n",
    "    temp = data['time.dayofyear']\n",
    "    \n",
    "    # grab every Xdoy from ensmean, fit npoly polynomial\n",
    "    # subtract polynomial from every Xdoy from members\n",
    "    detrend = []\n",
    "    for label,ens_group in train_data.groupby('time.dayofyear'):\n",
    "        Xgroup = data.where(temp == label, drop = True)\n",
    "        \n",
    "        curve = polynomial.polyfit(np.arange(0, ens_group.shape[0]), ens_group, npoly)\n",
    "        trend = polynomial.polyval(np.arange(0, ens_group.shape[0]), curve, tensor=True)\n",
    "        if len(train_data.shape) == 2: #combined lat and lon, so now 2\n",
    "            trend = np.swapaxes(trend,0,1) #only need to swap if theres a space dimension\n",
    "\n",
    "        diff = Xgroup - trend\n",
    "        detrend.append(diff)\n",
    "\n",
    "    detrend_xr = xr.concat(detrend,dim='time').unstack()\n",
    "    detrend_xr = detrend_xr.sortby('time')\n",
    "    \n",
    "    return detrend_xr\n",
    "\n",
    "def smooth_standard_deviation(std_doy, window=60):\n",
    "    # Extend the array by wrapping around for edge effects\n",
    "    extended_std_doy = xr.concat([std_doy[-window:], std_doy, std_doy[:window]], dim='dayofyear')\n",
    "    # Apply rolling mean and remove the extra days\n",
    "    smoothed_std = extended_std_doy.rolling(dayofyear=window, center=True).mean()\n",
    "    smoothed_std = smoothed_std[window:-window]\n",
    "    return smoothed_std\n",
    "\n",
    "def standardize_anomalies_with_smoothed_std(da):\n",
    "    # Compute day of year\n",
    "    doy = da['time'].dt.dayofyear\n",
    "    \n",
    "    # Group data by day of year and compute standard deviation\n",
    "    std_doy = da.groupby(doy).std('time')\n",
    "    \n",
    "    # Smooth the standard deviation using a 60-day rolling average\n",
    "    smoothed_std_doy = smooth_standard_deviation(std_doy, window=60)\n",
    "    # return smoothed_std_doy\n",
    "    # Standardize the anomalies by dividing by the smoothed standard deviation\n",
    "    standardized_da = da.groupby(doy) / smoothed_std_doy\n",
    "    \n",
    "    return standardized_da\n",
    "\n",
    "# # Example usage:\n",
    "# # standardized_anomalies = standardize_anomalies_with_smoothed_std(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b68062-dfdf-48a1-b36d-62ccd7076083",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/jhayron/tmp/ipykernel_214077/2618834057.py:8: RuntimeWarning: divide by zero encountered in divide\n",
      "  periods = np.abs(1 / freqs)\n"
     ]
    }
   ],
   "source": [
    "path_origins = '/glade/derecho/scratch/jhayron/Data4WRsClimateChange/ProcessedDataReanalyses/'\n",
    "name_reanalysis = 'ERA5'\n",
    "dataset = xr.open_dataset(f'{path_origins}Z500_{name_reanalysis}.nc')\n",
    "anoms = detrend_obs(dataset.Z,dataset.Z)\n",
    "std_anoms = standardize_anomalies_with_smoothed_std(anoms)\n",
    "filtered_anoms = fourierfilter(std_anoms)\n",
    "filtered_anoms = filtered_anoms.to_dataset(name='Z_anoms')\n",
    "filtered_anoms = filtered_anoms.drop_vars('dayofyear')\n",
    "path_output_anoms = f'{path_origins}Z500Anoms_{name_reanalysis}_v2.nc'\n",
    "filtered_anoms.to_netcdf(path_output_anoms)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4769b16d-3aba-4eac-84a0-2c5f814050ee",
   "metadata": {},
   "source": [
    "# All the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b497e302-e6da-4173-a4c9-c16388bde229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_anoms_reanalysis(name_reanalysis):\n",
    "    path_origins = '/glade/derecho/scratch/jhayron/Data4WRsClimateChange/ProcessedDataReanalyses/'\n",
    "    dataset = xr.open_dataset(f'{path_origins}Z500_{name_reanalysis}.nc')\n",
    "    anoms = detrend_obs(dataset.Z,dataset.Z)\n",
    "    std_anoms = standardize_anomalies_with_smoothed_std(anoms)\n",
    "    filtered_anoms = fourierfilter(std_anoms)\n",
    "    filtered_anoms = filtered_anoms.to_dataset(name='Z_anoms')\n",
    "    filtered_anoms = filtered_anoms.drop_vars('dayofyear')\n",
    "    path_output_anoms = f'{path_origins}Z500Anoms_{name_reanalysis}_v2.nc'\n",
    "    filtered_anoms.to_netcdf(path_output_anoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ab7cff5-b385-421e-a8e8-bea3ff7149fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/jhayron/tmp/ipykernel_214077/2618834057.py:8: RuntimeWarning: divide by zero encountered in divide\n",
      "  periods = np.abs(1 / freqs)\n"
     ]
    }
   ],
   "source": [
    "compute_anoms_reanalysis('JRA3Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d9a9abed-8f45-450a-b02b-32da9216638e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/jhayron/tmp/ipykernel_214077/2618834057.py:8: RuntimeWarning: divide by zero encountered in divide\n",
      "  periods = np.abs(1 / freqs)\n"
     ]
    }
   ],
   "source": [
    "compute_anoms_reanalysis('MERRA2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a0b4890-f0fd-486e-b7d7-2cfa01b26244",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/jhayron/tmp/ipykernel_214077/2618834057.py:8: RuntimeWarning: divide by zero encountered in divide\n",
      "  periods = np.abs(1 / freqs)\n"
     ]
    }
   ],
   "source": [
    "compute_anoms_reanalysis('NCEP_NCAR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d29dee2-f9a6-4da3-8eb2-a8ae34c703f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/glade/derecho/scratch/jhayron/tmp/ipykernel_214077/2618834057.py:8: RuntimeWarning: divide by zero encountered in divide\n",
      "  periods = np.abs(1 / freqs)\n"
     ]
    }
   ],
   "source": [
    "compute_anoms_reanalysis('NCEP_DOE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89cb201-6527-4f3e-adb4-b577f99bf917",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cnn_wr]",
   "language": "python",
   "name": "conda-env-cnn_wr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
