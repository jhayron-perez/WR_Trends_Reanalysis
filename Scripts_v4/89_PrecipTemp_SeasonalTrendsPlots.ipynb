{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c100939-2eeb-41cd-b934-590731f62de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import matplotlib.colors as mcolors\n",
    "\n",
    "import matplotlib.lines as mlines\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d02d8c5-c5ba-40e4-b4ec-5fa0166bcf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_reanalyses = ['ERA5',\n",
    "                   'JRA3Q',\n",
    "                   'NCEP_NCAR']\n",
    "\n",
    "dic_labels = {}\n",
    "for reanalysis in names_reanalyses:\n",
    "    labels_temp = pd.read_csv(f'../Data_v4/Labels/df_labels_{reanalysis}_v4.csv', \n",
    "                              parse_dates=True, index_col=0, names=['WR','distances'], skiprows=1)\n",
    "    labels_temp['season'] = labels_temp.index.month % 12 // 3 + 1  # This will give: 1=DJF, 2=MAM, 3=JJA, 4=SON\n",
    "    # Map season numbers to season names\n",
    "    season_map = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'}\n",
    "    labels_temp['season'] = labels_temp['season'].map(season_map)\n",
    "    dic_labels[reanalysis] = labels_temp\n",
    "\n",
    "\n",
    "dic_events = {}\n",
    "\n",
    "for ir, reanalysis in enumerate(names_reanalyses):\n",
    "    # Compute Overall Frequency of Each Class\n",
    "    df_labels = copy.deepcopy(dic_labels[reanalysis])\n",
    "    df_labels['season'] = df_labels.index.month % 12 // 3 + 1  # This will give: 1=DJF, 2=MAM, 3=JJA, 4=SON\n",
    "    # Map season numbers to season names\n",
    "    season_map = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'}\n",
    "    df_labels['season'] = df_labels['season'].map(season_map)\n",
    "    \n",
    "    # Step 1: Identify changes in class to find the start of each event\n",
    "    df_labels['shifted'] = df_labels['WR'].shift(1)\n",
    "    df_labels['start'] = df_labels['WR'] != df_labels['shifted']\n",
    "    df_labels['start_date'] = df_labels.index.where(df_labels['start'], pd.NaT)\n",
    "    df_labels['start_date'].fillna(method='ffill', inplace=True)\n",
    "    \n",
    "    # Step 2: Calculate the duration of each event\n",
    "    # Convert the Timedelta to its 'days' component\n",
    "    df_labels['duration'] = (df_labels.index - df_labels['start_date']).dt.days + 1\n",
    "    \n",
    "    # Step 3: Create the df_events DataFrame\n",
    "    # Group by 'start_date' and 'class' to get the duration of each class event\n",
    "    df_events = df_labels.groupby(['start_date', 'WR']).agg({'duration': 'max'}).reset_index()\n",
    "    \n",
    "    # Drop the temporary columns used for calculations\n",
    "    df_labels.drop(columns=['shifted', 'start', 'start_date', 'duration'], inplace=True)\n",
    "    \n",
    "    # Set 'start_date' as the index if needed\n",
    "    df_events.set_index('start_date', inplace=True)\n",
    "    df_events['season'] = df_events.index.month % 12 // 3 + 1  # This will give: 1=DJF, 2=MAM, 3=JJA, 4=SON\n",
    "    # Map season numbers to season names\n",
    "    season_map = {1: 'Winter', 2: 'Spring', 3: 'Summer', 4: 'Fall'}\n",
    "    df_events['season'] = df_events['season'].map(season_map)\n",
    "    df_events['year'] = df_events.index.year\n",
    "    dic_events[reanalysis] = df_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "82907f18-a6bb-4d56-abaf-7dc93e71d273",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import numpy as np\n",
    "\n",
    "def plot_composites(Composites, lon, lat, quantity_name, vmin, vmax, units, colormap, \\\n",
    "                    pathsave=None, multiply=1, p_values=False, p_threshold=0.05):\n",
    "    # Define the color levels and color map\n",
    "    levels = np.linspace(vmin, vmax, 11)\n",
    "    cmap = plt.get_cmap(colormap)\n",
    "\n",
    "    # Create the figure and axes\n",
    "    fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(9, 2 * 3), subplot_kw={'projection': ccrs.PlateCarree(central_longitude=-100)})\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    season_titles = ['Winter', 'Spring', 'Summer', 'Fall', 'All year']\n",
    "    # Iterate over each season (columns)\n",
    "    for iseason, season in enumerate(['Winter', 'Spring', 'Summer', 'Fall', 'All year']):\n",
    "        ax = axes[iseason]\n",
    "\n",
    "        # Plot the composite map\n",
    "        composite = Composites[season][quantity_name]\n",
    "\n",
    "        # Convert longitudes to -180 to 180 range\n",
    "        lon = (lon + 180) % 360 - 180\n",
    "        ax.set_extent([-80, 50, 20, 75], crs=ccrs.PlateCarree(central_longitude=-100))\n",
    "\n",
    "        # Plot the composite values using pcolormesh\n",
    "        cf = ax.pcolormesh(lon, lat, composite * multiply, vmin=vmin, vmax=vmax, \n",
    "                           cmap=cmap, transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Add hatching based on p-values if provided\n",
    "        if p_values is not None:\n",
    "            p_values_current = Composites[season][p_values]\n",
    "\n",
    "            # Create a mask where p-values are less than the threshold\n",
    "            significance_mask = (p_values_current <= p_threshold)\n",
    "\n",
    "            # Overlay hatching on significant areas\n",
    "            hatch_plot = ax.contourf(lon, lat, significance_mask, levels=[0.5, 1.5], \n",
    "                        colors='none', hatches=['...'], transform=ccrs.PlateCarree())\n",
    "            # Customize hatch properties if needed\n",
    "            for collection in hatch_plot.collections:\n",
    "                collection.set_edgecolor('white')  # Change hatch color\n",
    "                collection.set_linewidth(0.)     # Change hatch line width\n",
    "            # ax.contourf(lon, lat, significance_mask, levels=[0.5, 1], \n",
    "            #             colors='none', hatches=['xxx'], transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Add coastlines and gridlines\n",
    "        ax.coastlines()\n",
    "        ax.add_feature(cfeature.BORDERS, linestyle=':')\n",
    "        ax.gridlines(draw_labels=False, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "        # Set the title for each season column (first row only)\n",
    "        ax.set_title(season_titles[iseason], fontsize=13)\n",
    "\n",
    "        # Set font sizes for axes labels\n",
    "        ax.tick_params(axis='both', which='major', labelsize=10)\n",
    "        \n",
    "    fig.delaxes(axes[-1])\n",
    "\n",
    "    # Add a main title to the entire plot\n",
    "    fig.suptitle(f\"{quantity_name} - Composites\", fontsize=18, y=0.96, \n",
    "                 horizontalalignment='left', x=0.)\n",
    "\n",
    "    # Adjust layout to prevent overlapping\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Create colorbar\n",
    "    cbar_ax = fig.add_axes([0.6, 0.2, 0.35, 0.02])  # Position similar to the legend\n",
    "    cbar = fig.colorbar(cf, cax=cbar_ax, orientation='horizontal')\n",
    "    cbar.set_label(units, fontsize=13)\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "\n",
    "    # Save or show the plot\n",
    "    if pathsave:\n",
    "        plt.savefig(pathsave, bbox_inches='tight')\n",
    "    else:\n",
    "        plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e12de3-6642-4e66-9788-fece82e16c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "names_wrs = [\"Pacific High\",\"Pacific Trough\",\"Greenland High\",\"Atlantic High\",\"No WR\"]\n",
    "\n",
    "seasons = ['Winter','Spring','Summer','Fall','All year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e97fe58-54c0-4da3-ba4e-4d49628a6df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_names_vars = ['total_precip_da',\n",
    "                  'max_precip_da',\n",
    "                  'max_precip_5d_da',\n",
    "                  'meanmaxtemp_events',\n",
    "                  'meanmintemp_events']\n",
    "\n",
    "\n",
    "cmaps = ['seismic_r',\n",
    "        'seismic_r',\n",
    "        'seismic_r',\n",
    "        'bwr',\n",
    "        'bwr']\n",
    "\n",
    "\n",
    "cmaps_trends = ['BrBG',\n",
    "        'BrBG',\n",
    "        'BrBG',\n",
    "        'seismic',\n",
    "        'seismic']\n",
    "\n",
    "amplitude_map_diffs = [100, #totalprecip\n",
    "                      120, #max_precip_da 3\n",
    "                      100, #max_precip_5d_da\n",
    "                      1,\n",
    "                      1] #percentagewetdays_da\n",
    "\n",
    "amplitude_map_trends = [0.25*10, #totalprecip\n",
    "                       0.1*10, #max_precip_da\n",
    "                       0.25*10, #max_precip_5d_da\n",
    "                       0.2,\n",
    "                       0.25] #percentagewetdays_da\n",
    "\n",
    "multipliers = [10, #totalprecip\n",
    "               10, #max_precip_da\n",
    "               10, #max_precip_5d_da\n",
    "               10,\n",
    "               10] #percentagewetdays_da\n",
    "\n",
    "multipliers_diff = [100, #totalprecip\n",
    "               100, #max_precip_da\n",
    "               100, #max_precip_5d_da\n",
    "               1,\n",
    "               1] #percentagewetdays_da\n",
    "\n",
    "units_trend = ['mm/decade', #totalprecip\n",
    "              'mm/decade', #max_precip_da\n",
    "              'mm/decade', #max_precip_5d_da\n",
    "              r'$\\sigma$/decade',\n",
    "              r'$\\sigma$/decade'] #percentagewetdays_da\n",
    "\n",
    "units_diff = ['%', #totalprecip\n",
    "              '%', #max_precip_da\n",
    "              '%', #max_precip_5d_da\n",
    "              r'$\\sigma$',\n",
    "              r'$\\sigma$'] #percentagewetdays_da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a3b773d3-4d00-4c50-b535-69576de27aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_da = xr.open_dataset('/glade/derecho/scratch/jhayron/meanmaxtemp_events.nc')#.MaxTemp.compute()\n",
    "lon = temp_da.lon.compute()\n",
    "lat = temp_da.lat.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7510a056-758c-4a8b-b59a-a1edae3da045",
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_statistics_full = {}\n",
    "for name_var in list_names_vars:\n",
    "    try:\n",
    "        dic_temp = np.load(f'../Data_v4/TrendsPrecipitation/dic_statistics_{name_var}_seasonal.npy',\\\n",
    "            allow_pickle=True)[()]\n",
    "    except:\n",
    "        dic_temp = np.load(f'../Data_v4/TrendsTemperature/dic_statistics_{name_var}_seasonal.npy',\\\n",
    "            allow_pickle=True)[()]\n",
    "    dic_statistics_full[name_var] = dic_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5d849650-2e5c-4739-a257-2615ccacccbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "for ivar in [2]:\n",
    "# for ivar in range(len(list_names_vars)):\n",
    "    name_var = list_names_vars[ivar]\n",
    "    print(ivar)\n",
    "    plot_composites(dic_statistics_full[list_names_vars[ivar]],lon,lat,\\\n",
    "                        'trend',-amplitude_map_trends[ivar],amplitude_map_trends[ivar],\\\n",
    "                        units_trend[ivar],cmaps_trends[ivar],multiply=multipliers[ivar], \\\n",
    "                        p_values='trend_p_value',\n",
    "                        pathsave = f'../Figures_v4/TrendsSeasonal/{name_var}_trend_seasonal.png')\n",
    "\n",
    "    # plot_composites(dic_statistics_full[list_names_vars[ivar]],lon,lat,\\\n",
    "    #                     'diff_means',-amplitude_map_diffs[ivar],amplitude_map_diffs[ivar],\\\n",
    "    #                     units_diff[ivar],cmaps[ivar],multiply=multipliers_diff[ivar], \\\n",
    "    #                     p_values='p_value_bootstrap',\n",
    "    #                     pathsave = f'../Figures/trends_seasonal/{name_var}_diff_means_seasonal.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fa7abdf7-9637-4fd1-8624-bbc4fa6f9081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BrBG'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmaps_trends[ivar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4d0aa-9a83-48a3-b468-68e967686677",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cnn_wr]",
   "language": "python",
   "name": "conda-env-cnn_wr-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
